{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ae71ab-f517-4721-8802-5f3da6ca5969",
   "metadata": {},
   "source": [
    "## Implementation Adaptive PCA and Image denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6999c107-665e-4279-ac88-588fd5d6da29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from measure import compute_psnr, compute_ssim\n",
    "from utils import add_noisy, transform_wavelet\n",
    "from config import list_survey\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f480c1ba-6ba6-492e-a095-f5a015200d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "_IMG_PATH = '../images/lena512.bmp'\n",
    "_OUT_PATH = '../outputs'\n",
    "_LOG_PATH = '../logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ca8e8e-dd38-46d0-9560-afc83bc527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(_IMG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04f4818-e4ca-4c56-ad9a-0a27db6671b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img_origin = img_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43153aba-e4ac-4e62-9741-8c43fe37fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(img_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4b221a-dc13-4ed2-b321-13ba8e21329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_patches(I, patch_size = (7,7)):\n",
    "    \"\"\"\n",
    "    I is the image function\n",
    "    \"\"\"\n",
    "    patches_array = np.lib.stride_tricks.sliding_window_view(I, (7,7))\n",
    "    patches_array_rot = np.moveaxis(patches_array, 0, 1)\n",
    "    training_region = patches_array_rot.reshape(\n",
    "                                (patches_array_rot.shape[0]*patches_array_rot.shape[1],\n",
    "                                 patches_array_rot.shape[2]*patches_array_rot.shape[3]))\n",
    "    return training_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5ad85f-ad14-449b-9ce4-620ff20e8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_centroid_patches(hyper_params, I):\n",
    "    \"\"\"\n",
    "    I is the image function\n",
    "    \"\"\"\n",
    "    ## define size of mask follow size of feature map\n",
    "    ## mask is the array of centroids of patches\n",
    "    centroids_width = int((I.shape[0] - hyper_params['patch_size'])/hyper_params['stride_overlap']) + 1\n",
    "    centroids_height = int((I.shape[1] - hyper_params['patch_size'])/hyper_params['stride_overlap']) + 1\n",
    "    total_num_centroids = centroids_width*centroids_height\n",
    "    \n",
    "    ## define index matrix of the centroids array\n",
    "    centroids_map_index = np.arange(total_num_centroids)\n",
    "    centroids_map_index = centroids_map_index.reshape((centroids_height, centroids_width)).T\n",
    "    \n",
    "    return centroids_map_index, centroids_width, centroids_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a9108d-e125-4f0f-881e-58cd2c17d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principal_components(centroids_map_index, \n",
    "                      training_region, \n",
    "                      current_row, \n",
    "                      current_col,\n",
    "                      current_centroid_idx,\n",
    "                      hyper_params):\n",
    "    \n",
    "    [centroids_width, centroids_height] = centroids_map_index.shape\n",
    "\n",
    "    rmin = max(current_row - hyper_params['train_region_size'] - 1, 0)\n",
    "    rmax = min(current_row + hyper_params['train_region_size'], centroids_width)\n",
    "    cmin = max(current_col - hyper_params['train_region_size'] - 1, 0)\n",
    "    cmax = min(current_col + hyper_params['train_region_size'], centroids_height)\n",
    "\n",
    "    idx = centroids_map_index[rmin: rmax, cmin: cmax]\n",
    "    idx = (idx.T).flatten()\n",
    "    \n",
    "    ## training_region has size of 506*506*7*7\n",
    "    ## training_set has size 21*21*7*7\n",
    "    training_set = training_region[idx,:]\n",
    "    \n",
    "    ## denoise_region is signal with noise in middle 7*7\n",
    "    denoise_region = training_region[current_centroid_idx,:]\n",
    "    \n",
    "    ## calculate distance to selecting principal components\n",
    "    init_distance = (training_set[:, 0] - denoise_region[0])**2\n",
    "    init_distance = init_distance.reshape((init_distance.shape[0], 1))\n",
    "\n",
    "    for k in range(1, training_region.shape[1]):\n",
    "        partial_distance = (training_set[:, k] - denoise_region[k])**2\n",
    "        partial_distance = partial_distance.reshape((partial_distance.shape[0], 1))\n",
    "        init_distance += partial_distance\n",
    "\n",
    "    components_distance = init_distance/training_region.shape[1]\n",
    "    components_distance_sort = np.argsort(components_distance, axis=0)\n",
    "    \n",
    "    pc_index = idx[components_distance_sort[0:hyper_params['n_components']]]\n",
    "\n",
    "    return pc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b78391a-b52e-42b4-ace8-377f4198ddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(x):\n",
    "    \"\"\"\n",
    "    tranform from spatial domain to PCA domain\n",
    "    param:\n",
    "        x: MxN matrix (M dimensions, N trials)\n",
    "    return:\n",
    "        y: y=p*x\n",
    "        p: the transform matrix\n",
    "        v: the variance vector\n",
    "    \"\"\"\n",
    "    [m, n] = x.shape\n",
    "    \n",
    "    ## shift data to the center (subtract mean from every dimension)\n",
    "    mean_x = (np.mean(x, axis=1)).reshape((m, 1))\n",
    "    x = x - mean_x\n",
    "\n",
    "    covar_x = np.matmul(x,x.T)/(n-1)\n",
    "    \n",
    "    ## compute covariance matrix S for centered data \n",
    "    ## and find it eigenvectors b and eigenvalues λ.\n",
    "    [variance, transform_mat]= np.linalg.eig(covar_x)\n",
    "    \n",
    "    ## sort eigenvectors by corresponding eigenvalues in descending order\n",
    "    var_minus = -1 * variance\n",
    "    ind = np.argsort(var_minus, axis=0)\n",
    "\n",
    "    variance = variance[ind];\n",
    "    transform_mat = transform_mat[:, ind]\n",
    "\n",
    "    transform_mat = transform_mat.T\n",
    "    transform_coef = np.matmul(transform_mat, x)\n",
    "\n",
    "    return [transform_coef, transform_mat, variance, mean_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "978446f4-4ed0-461f-a1c1-ec9f60cba055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_pc_denoising(img_origin, img_noise, hyper_params):\n",
    "    \n",
    "    y_coeffs = transform_wavelet(img_noise)\n",
    "    var_noise_est = np.median(np.abs(y_coeffs[-1][-1]))/0.6745\n",
    "    \n",
    "    centroids_map_index, centroids_width, centroids_height = define_centroid_patches(hyper_params, img_noise)\n",
    "    training_region = divide_patches(img_noise)\n",
    "    denoise_set = np.zeros(training_region.T.shape)\n",
    "\n",
    "    print('*'*10,'Training','*'*10)\n",
    "    with tqdm(total = centroids_width * centroids_height) as pbar:\n",
    "        for i in range(centroids_width):\n",
    "            for j in range(centroids_height):\n",
    "\n",
    "                current_row = i\n",
    "                current_col = j\n",
    "\n",
    "                current_centroid_idx = current_col*centroids_width + current_row\n",
    "\n",
    "                pc_idx = get_principal_components(centroids_map_index, \n",
    "                              training_region, \n",
    "                              current_row, \n",
    "                              current_col,\n",
    "                              current_centroid_idx,\n",
    "                              hyper_params)\n",
    "\n",
    "                pc_idx = pc_idx.flatten()\n",
    "\n",
    "                [transform_coef, transform_mat, variance, mean_x] = pca_transform(training_region.T[:, pc_idx])\n",
    "\n",
    "                py = np.mean(transform_coef**2, axis=1)\n",
    "                py = py.reshape((py.shape[0], 1))\n",
    "\n",
    "                ## The variance of xi is estimated using the maximum likelihood estimator\n",
    "                px = np.maximum(np.zeros(py.shape), py - var_noise_est**2)\n",
    "\n",
    "                ## The LMMSE estimator for xi is xi = k*yi\n",
    "                wei = px/py\n",
    "\n",
    "                ## PCA inverse transformation \n",
    "                trans_coeff_est = ((transform_coef[:, 0]).T * (wei.T)).T\n",
    "                denoise_est = np.matmul(transform_mat.T, trans_coeff_est)\n",
    "                mean_x_reshape = mean_x[:, 0].reshape((mean_x[:, 0].shape[0], 1))\n",
    "\n",
    "                denoise_set[:, current_centroid_idx] = (denoise_est + mean_x_reshape)[:, 0]\n",
    "                pbar.update(1)\n",
    "\n",
    "    print('*'*10,'Reconstructing','*'*10)\n",
    "    img_recon = np.zeros(img_noise.shape)\n",
    "    img_wei = np.zeros(img_noise.shape)\n",
    "    row_idx = np.arange(0, centroids_width, 1)\n",
    "    col_idx = np.arange(0, centroids_height, 1)\n",
    "\n",
    "    k = 0\n",
    "    for i in range(hyper_params['patch_size']):\n",
    "        for j in range(hyper_params['patch_size']):\n",
    "            rv, cv = np.meshgrid(row_idx+i, col_idx+j)\n",
    "            img_recon[rv, cv] = img_recon[rv, cv] + (denoise_set[k, :].T).reshape((centroids_width, centroids_height))\n",
    "            img_wei[rv, cv] = img_wei[rv, cv] + 1\n",
    "            k+=1\n",
    "    img_denoise = img_recon/(img_wei)\n",
    "    \n",
    "    compare_psnr = (compute_psnr(img_gray, img_noise), compute_psnr(img_gray, img_denoise))\n",
    "    compare_ssim = (compute_ssim(img_gray, img_noise), compute_ssim(img_gray, img_denoise))\n",
    "    \n",
    "    return img_denoise, compare_psnr, compare_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb9d2f1-79cf-46b2-a8b5-113f8064105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(img_denoise, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65cff097-63ad-4785-b085-93d49b9670f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [07:51<00:00, 542.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 1/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [08:24<00:00, 507.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 2/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [08:25<00:00, 506.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 3/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [09:13<00:00, 462.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 4/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [09:05<00:00, 468.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 5/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [09:18<00:00, 458.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 6/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [09:32<00:00, 447.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 7/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [07:27<00:00, 572.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 8/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [07:40<00:00, 555.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 9/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [08:24<00:00, 507.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 10/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [08:55<00:00, 477.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 11/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [08:27<00:00, 504.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 12/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [10:05<00:00, 422.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 13/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [09:23<00:00, 454.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n",
      "==================== 14/16 ====================\n",
      "********** Training **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256036/256036 [10:50<00:00, 393.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Reconstructing **********\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for hyper_param in list_survey[1:]:\n",
    "    print('='*20, str(count) + '/' + str(len(list_survey)), '='*20)\n",
    "    img_noise, noise = add_noisy(img_gray, var=hyper_param['var_noise']**2)\n",
    "    img_denoise, compare_psnr, compare_ssim = adapt_pc_denoising(img_origin, img_noise, hyper_param)\n",
    "    \n",
    "    img_denoise_format_int = (((img_denoise - img_denoise.min()) / (img_denoise.max() - img_denoise.min())) * 255.9).astype(np.uint8)\n",
    "    img_denoise_array = Image.fromarray(img_denoise_format_int)\n",
    "    img_save_name = 'vnoise' + '_' + str(hyper_param['var_noise']) + '_' + 'npc' + '_' + str(hyper_param['n_components']) + '.png'\n",
    "    img_denoise_array.save(os.path.join(_OUT_PATH,img_save_name).replace('\\\\','/'))\n",
    "    \n",
    "    log_save_name = 'vnoise' + '_' + str(hyper_param['var_noise']) + '_' + 'npc' + '_' + str(hyper_param['n_components']) + '.npy'\n",
    "    measures = []\n",
    "    measures.append(compare_psnr[0])\n",
    "    measures.append(compare_psnr[1])\n",
    "    measures.append(compare_ssim[0])\n",
    "    measures.append(compare_ssim[1])\n",
    "    measure_array = np.array(measures)\n",
    "    log_file = open(os.path.join(_LOG_PATH,log_save_name).replace('\\\\','/'),'wb')\n",
    "    np.save(log_file,measure_array)\n",
    "    \n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385800b-10ec-4924-8fd7-a6cfd8593c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
